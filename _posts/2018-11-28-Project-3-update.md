---
layout: post
title: "Update on 'Automation, AI, Algorithms' Project"
description: "A short blog post update on CAET project 3"
category: articles
comments: false
---

The lack of transparency of AI and machine learning systems in society is considered to be one of the greatest dangers of this rapidly scalable and versatile technology. AI as a technological system is characterized by a rigidity in protocol development and performance metrics. In contrast, the human intelligence that it aspires to, is characterized by heuristics, emotion, and judgement. We know little about how the brain works or how it develops a sense of justice, ethics, and philosophy. As AI systems foray into the uncharted space between the rigor of engineered intelligence and the heuristic of human intelligence, they are increasingly susceptible to embedding the biases and flaws that arise from the differences between data and our cultural worldview.

In the previous post, I shared that my initial hunch for this project was to direct it toward discovering metrics for equitable and responsible development of large data-driven systems. Delving deeper into the matter brought out increasingly complex technical, as well as philosophical and ethical issues that I felt simply couldn't be trivialized with an engineered 'solution'. This idea also seemed to approach the project from a heavily technical perspective rather than an artistic one. So I flipped my approach and tried to explore how I could use art to facilitate social change through a more informed collective critique of AI and machine learning.

I still intended to address this duality in AI, but since any tool only mirrors the motives of the wielder, I wanted to focus on how this system is engineered and what the learning data actually conveys. The concept of a problem state space is central to AI. This problem state space contains the multi-dimensional data points from which the AI has learnt, and to some degree is representative of the AI's 'mind'. Through clustering or regression, associations are built through which the AI can process and respond to new data. The patterns that the AI finds simply reflects how the dataset was engineered, and the inferences drawn from these patterns are ultimately subject to human interpretation. Through this art project, I want to explore tangible representations of this multi-dimensional AI 'mind', and question the authority and supposed objectivity of 'blackbox' AI systems by exposing multiple interpretations of data.

**The Medium**

The current idea of the artwork is to suspend a few hundred uniquely dimensioned 3D printed plastic cubes in a seemingly random 'cloud'. This cloud is representative of datapoints with unique multi-dimensional information in a static state space. As you walk around the cloud, the different viewing angles will cause different shapes to emerge in the cloud with the help of a specific lighting setup, that would not be discernible from any other angle. This feature seeks to highlight that even though this data seems absolute and un-changing, your inference of what it represents is determined by your perspective on the data.

The digital model of this sculpture is still under progress, but here's just a picture of a random cloud of uniquely-dimensioned cubes. I wasn't able to add an interactive 3D model to this page. I am still working on showing different shapes from different viewing angles.

![1]({{ site.url }}/images/datacloud1.png)
